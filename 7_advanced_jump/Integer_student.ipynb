{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integer Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last session, you learned about the JuMP ecosystem and solved simple continuous optimization problems.\n",
    "You've probably worked with JuMP to solve even more complicated LPs in 15.081.\n",
    "In this session, we'll look into other types of problems, namely, **integer and nonlinear optimization problems**.\n",
    "\n",
    "In the first half of the session, we'll focus on (Mixed) Integer Programming, which studies optimization problems in which some or all of the variables are restricted to be integers. Integer programs model situations where we need to make discrete decisions, which are frequently encountered in Operations Research.\n",
    "\n",
    "**REMARK:** The simplest case of IP, namely, Binary Integer Linear Programming is NP-complete. So shouldn't we just go home?\n",
    "\n",
    "\n",
    "## I. IP Basics\n",
    "\n",
    "### I.1. Ryan's Unbounded Knapsack\n",
    "\n",
    "Every morning, Ryan goes to the coffee shop and gets as much coffee as possible to be productive during the day.\n",
    "There are $N$ types of coffee he can choose from, each with different caffeine content $v_i$ and price $w_i$ (you may assume that the coffee shop has an infinite supply of each coffee type).\n",
    "Apparently Ryan doesn't want to go bankrupt, so he won't spend more that $C$ dollars. \n",
    "How does he choose what coffees to buy to maximize his caffeine intake and hence his productivity?\n",
    "\n",
    "We can model Ryan's situation as a (pure) integer optimization problem:\n",
    "\n",
    "\\begin{align*}\n",
    "\\max& \\sum_{i=1}^N v_i x_i \\\\\n",
    "\\text{s.t.}& \\sum_{i=1}^N w_i x_i \\leq C \\\\\n",
    "& x_i \\in \\mathbb{Z}_{\\geq 0} \\quad \\forall i = 1,\\ldots,N\n",
    "\\end{align*}\n",
    "\n",
    "Variable $x_i$ expresses the number of coffees of type $i$ Ryan will buy. (Ryan's favorite coffee shop only sells one-sized coffee, so all variables are constrained to be integer.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Toy Example\n",
    "\n",
    "In particular, let's look into the following toy problem:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\max\\:& x + y + 1.5 z \\\\\n",
    "    \\text{s.t.}\\:& x + 2y + 3z \\leq 5.5 \\\\\n",
    "    & x, y, z \\in \\mathbb{Z}_{\\geq 0}\n",
    "\\end{align*}\n",
    "\n",
    "How would you solve this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Gurobi, LinearAlgebra\n",
    "\n",
    "# Small toy problem from above\n",
    "values = [1,1,1.5]\n",
    "weights = [1,2,3]\n",
    "C = 5.5\n",
    "\n",
    "# Another small problem (from JuMP documentation)\n",
    "# values = [5, 3, 2, 7, 4]\n",
    "# weights = [2, 8, 4, 2, 5]\n",
    "# C = 10\n",
    "\n",
    "function solve_knapsack(values, weights, C)\n",
    "    N = length(values)\n",
    "    knapsackModel=Model(Gurobi.Optimizer)\n",
    "    \n",
    "    #############\n",
    "    #############\n",
    "    # Complete...\n",
    "    \n",
    "    \n",
    "        # Hint: when defining the capacity constraint, name it \"capacity\"\n",
    "    \n",
    "    \n",
    "    #############\n",
    "    #############\n",
    "    \n",
    "    print(knapsackModel)\n",
    "    optimize!(knapsackModel)\n",
    "    return value.(x), objective_value(knapsackModel), knapsackModel\n",
    "end\n",
    "\n",
    "x_opt, val_opt, model = solve_knapsack(values, weights, C)\n",
    "println(\"Optimal solution = $x_opt \\nOptimal value = $val_opt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying the Problem\n",
    "During happy hour, the coffee shop sells coffee of type z with a 50% discount. Thankfully, Ryan has already computed the optimal solution before the discount, so he hopes that he can slightly modify his existing model and resolve it, taking advantage of any knowledge he already has.\n",
    "    \n",
    "In the latest versions of JuMP, we can modify and delete constraints as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"\\nModel before modification:\")\n",
    "print(model)\n",
    "println(\" --> Objective value = $(objective_value(model))\")\n",
    "\n",
    "# Now let's modify the model\n",
    "z = all_variables(model)[3]\n",
    "con = constraint_by_name(model,\"capacity\")\n",
    "set_normalized_coefficient(con, z, 1.5)\n",
    "\n",
    "println(\"\\nModel after modification:\")\n",
    "print(model)\n",
    "println()\n",
    "optimize!(model)\n",
    "println(\" --> Objective value = $(objective_value(model))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ι.2. Branch and Bound Tree\n",
    "\n",
    "Although IP solvers are often viewed as black boxes, in what follows, we'll next try to \"open\" the box.\n",
    "\n",
    "For simplicity, we first consider a pure binary optimization problem over two variables (there are only two types of coffee, and Ryan can get at most one cup of each):\n",
    "\n",
    "\\begin{align*}\n",
    "\\max& \\quad v_x x + v_y y\\\\\n",
    "\\text{s.t.}& \\quad w_x x + w_y y \\leq C \\\\\n",
    "& \\quad x,y \\in \\{0,1\\}\n",
    "\\end{align*}\n",
    "\n",
    "The simple way is just to consider each possible value for $x$ and $y$ and compare the cost.\n",
    "\n",
    "![alt text](img/tree_1.png)\n",
    "\n",
    "In the general case, this would lead to $2^N$ possible collections of items. After Ryan has examined all of them, he just chooses the best set among the ones he can afford."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's visualize this approach as a search tree:\n",
    "\n",
    "![alt text](img/tree_2.png)\n",
    "\n",
    "It's rooted at what we call the **relaxation**: none of variables have integrality enforced. As we go down leaves of the tree, we pick a variable to **branch** on, and create two descended nodes that fix that variable to one of its possible values. If we follow the tree all the way to the bottom, we reach our enumeration from before.\n",
    "\n",
    "As we go down the arcs of the tree we restrict our problem more and more, we must have that:\n",
    "\n",
    ">If node ``q`` is descended from node ``p``, we must have that the optimal cost of subproblem ``q`` is no more than that for node ``p``\n",
    "\n",
    "This leads us to a powerful tool in solving these enumeration problems: \n",
    "\n",
    ">If I can show you that the optimal cost for subproblem ``q`` is _less_ than the optimal cost for the original problem, the same is true for any descendent of ``q``. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "That is, we can **prune** the tree and safely discard some nodes, kind of like this:\n",
    "\n",
    "![alt text](img/tree_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to our Toy Example\n",
    "\n",
    "Hopefully we're now familiar with how the branch and bound tree works for IP's with binary variables.\n",
    "Let's turn back to our toy example that contains nonnegative integer variables and see how the branch and bound tree would be built.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\max\\:& x + y + 1.5 z \\\\\n",
    "    \\text{s.t.}\\:& x + 2y + 3z \\leq 5.5 \\\\\n",
    "    & x, y, z \\in \\mathbb{Z}_{\\geq 0}\n",
    "\\end{align*}\n",
    "\n",
    "* First, we solve the LP relaxation and get $(x^*,y^*,z^*) = (5.5,0,0)$. \n",
    "* This isn't integer feasible, so we branch on $x$, which is the only non-integer variable. We construct two subproblems:\n",
    "    - Subproblem 1 is:\n",
    "        \\begin{align*}\n",
    "            \\max\\:& x + y + 1.5 z \\\\\n",
    "            \\text{s.t.}\\:& x + 2y + 3z \\leq 5.5 \\\\\n",
    "            & x \\leq 5\n",
    "            & x, y, z \\in \\mathbb{Z}_{\\geq 0}\n",
    "        \\end{align*}\n",
    "        The optimal solution to this subproblem is obtained for $(x^*,y^*,z^*) = (5,0,0)$ and is integer feasible with an optimal cost of $5.$ This is the best solution we've found so far, so we update our lower bound.\n",
    "    - Subproblem 2 is: \n",
    "        \\begin{align*}\n",
    "            \\max\\:& x + y + 1.5 z \\\\\n",
    "            \\text{s.t.}\\:& x + 2y + 3z \\leq 5.5 \\\\\n",
    "            & x \\geq 6\n",
    "            & x, y, z \\in \\mathbb{Z}_{\\geq 0}\n",
    "        \\end{align*}\n",
    "        This is infeasible. \n",
    "* We've exhausted the tree, so we have our optimal solution!\n",
    "\n",
    "The branch-and-bound scheme can end up solving many subproblems, so for it to work well, we need to *prune* large portions of the tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ι.3. Branch and Bound Algorithm\n",
    "We'll keep track of a global _lower bound_ $LB$ for our problem. Each node ``q`` will have an upper bound $UB_q$ that it inherents from its parent. If we get to the point where we have solved all subproblems (or, ideally, pruned off a great deal of them), we know that we're optimal. To do this we'll also keep track of a list $L$ of subproblems left to solve; initially, it's just the relaxation. The procedure is:\n",
    "\n",
    "While $L$ is not empty, pick a subproblem ``q`` out of our list $L$ and solve it. \n",
    "1. ``if`` ``q`` is infeasible, ``continue``\n",
    "2. ``if`` the solution is integer feasible, update the lower bound $LB$ if the cost is higher than what we had before\n",
    "3. ``if``  the relaxation value is less than our global $LB$ ``continue``\n",
    "4. ``else`` pick a non-integer variable $i$ and _branch_ by adding two subproblems to $L$: \n",
    "    * One with $x_i = 0$\n",
    "    * Another with $x_i = 1$\n",
    "\n",
    "Branch-and-bound is sometimes called an _implicit enumeration_ scheme because of step 3: we avoid solving any subproblems that we can prove won't produce the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4. Ιmplementation of the Branch and Bound Algorithm in Gurobi\n",
    "\n",
    "The \"magic\" of modern MIP solvers largely comes down to pruning massive portions of the tree. Some of this is essentially beyond your control, but there are certain things which you can do. This is the topic of Part II of this IP crash course.\n",
    "\n",
    "In what follows, we focus on **Gurobi**, a commercial solver that solves Mixed Integer LPs/QPs/QCQPs. (You can get the full picture of what solvers JuMP supports and what types of problems you can solve with each of them by visiting http://www.juliaopt.org/JuMP.jl/latest/installation/ and scrolling a bit down.)\n",
    "\n",
    "What are the ingredients of Gurobi's branch and bound implementation?\n",
    " - **Presolve**: reduce problem size via removal of redundant constraints and variable substitutions.\n",
    " - **Sophisticated Implementations of Continuous Optimization Methods**: simplex-based, barrier-based.\n",
    " - **Cutting Planes**: over the course of the solution process, add cuts that tighten the model and remove potential undesired fractional solution. Here is an example:\n",
    "     - Consider the constraint $6 x_1 + 5 x_2 + 7 x_3 + 4 x_4 + 5 x_5 \\leq 15$, where $x_1$ through $x_5$ are restricted to be binary. \n",
    "     - Suppose in addition that we have just solved an LP relaxation and that these variables take the following values in this LP relaxation: $x_1 = 0, x_2 = 1, x_3 = x_4 = x_5 = \\frac{3}{4}$. \n",
    "     - This undesirable solution can be excluded with the following observation: since $7 + 4 + 5 = 16 > 15$, it is not possible that $x_3 = x_4 = x_5 = 1$, and hence that the following new inequality is a valid addition to the given MIP: $x_3 + x_4 + x_5 \\leq 2$. Since $\\frac{3}{4} + \\frac{3}{4} + \\frac{3}{4} = \\frac{9}{4} > 2$, the new inequality cuts off the current solution.\n",
    " - **Heuristics**: e.g., randomized rounding.\n",
    " - **Branch Variable Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ι.5. Understanding Gurobi's Output\n",
    "First, it solves the LP relaxation and reports back:\n",
    "```\n",
    "Root relaxation: objective 4.014179e+00, 18 iterations, 0.00 seconds\n",
    "```\n",
    "Now it explores the branch-and-bound tree, and updates us as it goes along. Let's look at just the first line:\n",
    "```\n",
    "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
    " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
    "\n",
    "     0     0    4.01418    0    7    2.35937    4.01418  70.1%     -    0s\n",
    "```\n",
    "We see that the information is broken down into four main columns:\n",
    "\n",
    "1. ``Nodes``: Global node information\n",
    "    * how many nodes have we looked at\n",
    "    * how many do we have in our queue\n",
    "2. ``Current Node``\n",
    "    * objective\n",
    "    * depth in the tree\n",
    "    * number of noninteger variables in the solution\n",
    "3. ``Objective Bounds``\n",
    "    * Best incumbent (lower bound)\n",
    "    * node upper bound\n",
    "    * the gap between the two\n",
    "4. ``Work``\n",
    "    * average simplex iterations per node\n",
    "    * total elapsed time\n",
    "\n",
    "Finally, we get a neat summary of the cutting planes Gurobi found useful:\n",
    "```\n",
    "Cutting planes:\n",
    "  Gomory: 3\n",
    "  Cover: 2\n",
    "  MIR: 5\n",
    "```\n",
    "All told, we explored 190  nodes, much less than the $2^{100}$ we were worried about. All this only took 698 simplex iterations and 0.21 seconds.\n",
    "\n",
    "Now what about those ``H``s that appear? That tells us that Gurobi ran a heuristic and found a new best solution. You can see for yourself, as the incumbent value increases while the bound remains the same:\n",
    "```\n",
    "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
    " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
    "\n",
    "     0     0    4.01418    0    7    2.35937    4.01418  70.1%     -    0s\n",
    "H    0     0                       3.3780464    4.01418  18.8%     -    0s\n",
    "```\n",
    "You'll also sometimes see a ``*`` instead of the ``H``, which says that the feasible solution came from branching instead of heuristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ΙΙ. Advanced IP\n",
    "\n",
    "Now that we've mastered the basics, we'll look into more advanced stuff; we'll try to interact with the solver and intervene in the solving process.\n",
    "\n",
    "### II.1. Lazy Constraints in Ryan's Unbounded Knapsack\n",
    "\n",
    "Ryan is willing to sacrifice some caffeine intake to switch between espresso, cold brew, and flat white.\n",
    "In particular, he wants the maximum difference between the selected quantities of any two types of coffee to be no more that $μ$.\n",
    "This requirement leads to $2{ n \\choose 2 }$ constraints.\n",
    "Instead of enumerating all of them and adding them a priori to the model, we may use a technique known as **lazy constraints**.\n",
    "\n",
    "In particular, every time our solver reaches a new solution, for example with a heuristic or by solving a problem at a node in the branch and bound tree, it will give the user the chance to provide constraint(s) that would make the current solution infeasible.\n",
    "\n",
    "\n",
    "#### Implementing Lazy Constraints\n",
    "\n",
    "MIP solvers implement lazy constraints via a technique known as **solver callback**.\n",
    "JuMP currently supports **solver-independent callbacks** for CPLEX, GLPK, and Gurobi.\n",
    "\n",
    "**REMARK:** Part of the major changes JuMP underwent between versions 0.18 and 0.19 was the removal of solver-independent callbacks. Support for solver-independent callbacks was restored during the last 1-2 months. \n",
    "\n",
    "There are three important steps to providing a lazy constraint callback in JuMP. \n",
    "- **Callback function**: a function that will analyze the current solution. This function takes as argument a reference to the callback management code inside JuMP. Currently, the only thing we may query in a callback is the primal value of the variables using the function \"callback_value\". If we need any other information, we may use a **solver-dependent** callback instead (for an example, look here https://discourse.julialang.org/t/solver-dependent-callbacks-in-jump-how-to-do-it-right/32130).\n",
    "- **Lazy constraint**: after analyzing the current solution, we generate a new constraint using the \"con = @build_constraint(...)\" macro and submit it to the model via the MOI interface \"MOI.submit(model, MOI.LazyConstraint(cb), con).\"\n",
    "- **Lazy constraint callback**: we again use the MOI interface to tell the solver which function should be used for lazy constraint generation \"MOI.set(model, MOI.LazyConstraintCallback(), my_callback).\"\n",
    "\n",
    "#### Reasons to Use Lazy Constraints\n",
    "\n",
    "- The model involves a large number of constraints, many of which will most likely be redundant or non-binding near an optimal solution. In many cases, it can even be intractable to generate all the constraints. (E.g., in the TSP, which we'll see shortly after, the number of constraints grows exponentially with the number of nodes in the network; instead of generating them a priori, we run the so-called subtour elimination routine every time we obtain a solution.)\n",
    "- In some cases, we may be unable to identify all constraints at the time the model is specified. The feasibility and optimality cuts generated during Benders decomposition fall into this category; we discover them by solving one or more subproblems at certain points in the search for the solution to the master problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function solve_fair_knapsack(values, weights, C, max_diff)\n",
    "    N = length(values)\n",
    "    fairKnapsackModel=Model(Gurobi.Optimizer)\n",
    "    @variable(fairKnapsackModel, x[1:N]>=0, Int)\n",
    "    @constraint(fairKnapsackModel, dot(x, weights) <= C)\n",
    "    @objective(fairKnapsackModel, Max, dot(x, values))\n",
    "    lazy_called = false\n",
    "    function my_callback(cb) # what is cb? what data can we access during callback?\n",
    "        lazy_called = true\n",
    "        x_vals = callback_value.(Ref(cb), x)\n",
    "        \n",
    "        #############\n",
    "        #############\n",
    "        # Complete...\n",
    "\n",
    "\n",
    "        #############\n",
    "        #############\n",
    "        \n",
    "    end \n",
    "\n",
    "    #############\n",
    "    #############\n",
    "    # Complete...\n",
    "\n",
    "\n",
    "    #############\n",
    "    #############\n",
    "    \n",
    "    print(fairKnapsackModel)\n",
    "    println(\"\\n*** Callback called? $lazy_called\\n\\n\")\n",
    "    optimize!(fairKnapsackModel)\n",
    "    println(\"\\n*** Callback called? $lazy_called\\n\\n\")\n",
    "    return value.(x), objective_value(fairKnapsackModel), fairKnapsackModel\n",
    "end\n",
    "\n",
    "max_diff = 2\n",
    "xf_opt, valf_opt, model = solve_fair_knapsack(values, weights, C, max_diff)\n",
    "println(\"Optimal solution = $xf_opt \\nOptimal value = $valf_opt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Callback Types\n",
    "\n",
    "JuMP 0.20 supports three types of callbacks:\n",
    "\n",
    "- **Lazy constraints**: See previous section.\n",
    "        \n",
    "        \n",
    "- **User cuts**: User cuts provide a way for the user to tighten the LP relaxation using problem-specific knowledge that the solver cannot infer from the model and hence cannot utilize when generating cuts like the ones we saw earlier (Gurobi's cutting planes component).\n",
    "\n",
    "      MOI.submit(model, MOI.UserCut(cb), con)\n",
    "      \n",
    "      MOI.set(model, MOI.UserCutCallback(), my_callback_function)\n",
    "\n",
    "    - Importantly, user cuts **should not change the set of integer feasible solutions** and can only remove fractional solutions; if we add a cut that removes an integer solution, the solver may return an incorrect solution. **That's the main difference between user cuts and lazy constraints.**\n",
    "\n",
    "    - Just like with lazy constraints, when a MIP solver reaches a new node in the branch-and-bound tree, it will give the user the chance to provide cuts to make the current relaxed (fractional) solution infeasible in the hopes of obtaining an integer solution.\n",
    "    \n",
    "    - Generally speaking, solvers can add general purpose cuts (e.g., CG, split, MIR) and structure specific cuts (e.g., knapsack cover, clique) better than we can. However, we are better at adding problem specific cuts. Therefore, when trying to improve bound quality, a good place to start is identifying problem structure which a solver hasn't found, and exploiting this problem structure.\n",
    "    \n",
    "    \n",
    "- **Heuristic solutions**: By heuristic solution we refer to the method that the solver applies during the solution process to find integer solutions quicker than plain branch-and-bound would and tighten the bound, allowing us to fathom nodes quicker and to tighten the integrality gap.\n",
    "    \n",
    "      status = MOI.submit(model, MOI.HeuristicSolution(cb), [x], [floor(Int, x_val)]) # accept/reject/unknown\n",
    "            \n",
    "      MOI.set(model, MOI.HeuristicCallback(), my_callback_function)\n",
    "\n",
    "    - Solvers' heuristics are based on neighborhood search (e.g., flipping binary variables, fix some variables and solve a smaller MILP), rounding or \"polishing\" existing solutions.\n",
    "\n",
    "    - This callback enables us to add heuristics of our own if we have some special insight into the problem structure that the solver is not aware of. For instance, if we're solving a knapsack problem, one simple heuristic is to add a **greedy solution** where we iteratively add the best available item to the sack until you run out of room. This will often be a very good solution, and is a simple example of a problem-specific heuristic scheme.\n",
    "\n",
    "\n",
    "- Previous versions of JuMP also supported **informational callbacks**, which were used to track solver progress without actually changing the algorithm by adding cuts or heuristic solutions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3. Improving Branch and Bound's Performance\n",
    "We care about four distinct attributes:\n",
    "\n",
    "1) **Correctness**: Are \"feasible\" solutions feasible? Are \"optimal\" solutions optimal?\n",
    "\n",
    "2) **Time taken**: Fast is every user's favourite feature.\n",
    "\n",
    "3) **Bound quality**: How good is the lower bound?\n",
    "\n",
    "4) **Solution quality**: How good is the best solution identified?\n",
    "\n",
    "**In general, you should try to solve a problem in a quick-and-dirty way, and see which attribute needs working on.** E.g, if you find the optimal solution straight away but need lots of time to prove optimality then focus on bound quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.4. Solver Parameters\n",
    "Gurobi (and other high-quality solvers such as CPLEX) allow you to tweak a wide range of different parameters; sometimes tuning these can drastically improve performance. It can be kind of intimidating, though: Gurobi has over 100 parameters (and CPLEX has even more!), so which are the important ones?\n",
    "\n",
    "Some useful ones:\n",
    "\n",
    "Gurobi: \n",
    "* TimeLimit: how long the solver will run before giving up\n",
    "* MIPGap: termination criterion for relative gap $\\frac{UB-LB}{LB}$\n",
    "* MIPFocus: High-level controls on solver priority (proving optimality or increasing bound or finding optimal solution)\n",
    "* VarBranch: MIP branching strategy (pseudocost/strong branching)\n",
    "* Cuts: How aggresive we want to be in our cut generation (higher values improve lower bound but might slow overall process).\n",
    "\n",
    "How to set these parameters in JuMP 0.20?\n",
    "    \n",
    "    set_parameter(model, \"MIPGap\", 1e-4)\n",
    "    set_time_limit_sec(model, 20.0)\n",
    "\n",
    "Is that it? Well, no, but you probably need domain knowledge about your problem to go much further. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.5. The Travelling Salesman Problem\n",
    "The basic problem is that we are given a set of co-ordinates $(a_i, b_i)_{i=1}^n$ corresponding to a set of $n$ nodes in a graph, and we need to decide which $n$ of the $n^2$ arcs in the graph we will use to tour the graph, wherein we visit each node exactly once, at _minimum_ total cost. Let's formulate this as an integer program!\n",
    "\n",
    "Let the cities be indexed from 1 to N.\n",
    "Let $d_{ij}$ be the distance between city $i$ and city $j$.\n",
    "\n",
    "Decision variables: $x_{ij}=\\begin{cases} 1,\\quad \\text{if city $i$ and city $j$ are adjacent in the shortest tour}\\\\\n",
    "0,\\quad \\text{otherwise.}\\end{cases}$\n",
    "\n",
    "N.B. $x_{ij}$ and $x_{ji}$ are redundant ($x_{ij}=x_{ji}$), so we only define the variable $x_{ij}$ for $i < j$. Then we can formulate the following integer program.\n",
    "\n",
    "$$\n",
    "\\underset{x}{\\min}\\ \\sum_{i=1}^{N-1}\\sum_{j=i+1}^N d_{ij}x_{ij} \\\\\n",
    "\\text{s.t.}\\quad \n",
    "\\sum_{j=i+1}^N x_{ij} + \\sum_{j=1}^{i-1}x_{ji} = 2 \\quad\\forall i, 1\\le i \\le N \\\\\n",
    "x_{ij}\\in\\{0,1\\}\\quad\\forall i,j \\text{ s.t. } 1\\le i < j \\le N\n",
    "$$\n",
    "\n",
    "However, if we attempt to solve this problem, we will find that we get an infeasible solution, with multiple disjoint subtours. \n",
    "\n",
    "![alt text](img/tsp1.png)\n",
    "\n",
    "Yikes! Our formulation is missing something! What are some potential ways to fix it?\n",
    "\n",
    "One common way is **subtour elimination** constraints, to prevent the final solution from having any small cycles, i.e. cycles that do not include all the nodes.\n",
    "\n",
    "Given a subtour $S\\subset \\{1,\\ldots,N\\}$, a subtour elimination constraint looks like:\n",
    "$$\\sum_{i\\in S} \\left(\\sum_{j\\notin S, j > i}x_{ij}+\\sum_{j\\notin S, j < i}x_{ji}\\right) \\ge 2.$$\n",
    "\n",
    "As $N$ grows larger, the number of subtour elimination constraints grows exponentially. It is therefore impractical to add all of these constraints into the model.\n",
    "\n",
    "Instead, we generate these constraints lazily. Every time Gurobi has an incumbent solution, we find the shortest subtour in the solution, and add a lazy constraint eliminating this particular subtour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A TSP solver\n",
    "\n",
    "We begin by loading the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Gurobi, Test, LinearAlgebra, DelimitedFiles, Gadfly, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function to extract a n+1 dimensional vector representing a tour from an n x n symmetric matrix representing a solution provided by a solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function extractTour(n, sol)\n",
    "    tour = [1]  # Start at city 1 always\n",
    "    cur_city = 1\n",
    "    while true\n",
    "        # Look for first arc out of current city\n",
    "        for j = 1:n\n",
    "            if sol[cur_city,j] >= 0.5-1e-6\n",
    "                # Found next city\n",
    "                push!(tour, j)\n",
    "                # Don't ever use this arc again\n",
    "                sol[cur_city, j] = 0.0\n",
    "                sol[j, cur_city] = 0.0\n",
    "                # Move to next city\n",
    "                cur_city = j\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        # If we have come back to 1, stop\n",
    "        if cur_city == 1\n",
    "            break\n",
    "        end\n",
    "    end  # end while\n",
    "    return tour\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function which acts as a seperation oracle, which is a fancy way of saying that it either identifies a subtour which should be banned from the set of all possible solutions, or decides that the current solution is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input:\n",
    "#  n        Number of cities\n",
    "#  sol      n-by-n 0-1 symmetric matrix representing solution\n",
    "# Outputs:\n",
    "#  subtour  n length vector of booleans, true iff in a particular subtour\n",
    "#  subtour_length   Number of cities in subtour (if n, no subtour found)\n",
    "function findSubtour(n, sol)\n",
    "    # Initialize to no subtour\n",
    "    subtour = fill(false,n)\n",
    "    #=\n",
    "    # Always start looking at city 1\n",
    "    cur_city = 1\n",
    "    =#\n",
    "    # Start looking at a random city: much faster because we explore different subtours\n",
    "    cur_city=rand(1:n)\n",
    "    subtour[cur_city] = true\n",
    "    subtour_length = 1\n",
    "    while true\n",
    "        # Find next node that we haven't yet visited\n",
    "        found_city = false\n",
    "        indices = shuffle(1:n)\n",
    "        for j = 1:n\n",
    "            if !subtour[indices[j]]\n",
    "                if sol[cur_city, indices[j]] >= 1 - 1e-6\n",
    "                    # Arc to unvisited city, follow it\n",
    "                    cur_city = indices[j]\n",
    "                    subtour[indices[j]] = true\n",
    "                    found_city = true\n",
    "                    subtour_length += 1\n",
    "                    break  # Move on to next city\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        if !found_city\n",
    "            # We are done\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    return subtour, subtour_length\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function which solves TSP, given a matrix of city locations, using an optimization solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   cities  n-by-2 matrix of (x,y) city locations\n",
    "# Output:\n",
    "#   path    Vector with order to cities are visited in\n",
    "function solveTSP(cities; time_limit=30.0)\n",
    "\n",
    "    n = size(cities)[1]\n",
    "    # Calculate pairwise distance matrix\n",
    "    dist = zeros(n, n)\n",
    "    for i = 1:n\n",
    "        for j = i:n\n",
    "            d = norm(cities[i,1:2] - cities[j,1:2])\n",
    "            dist[i,j] = d\n",
    "            dist[j,i] = d\n",
    "        end\n",
    "    end\n",
    "\n",
    "    m = Model(Gurobi.Optimizer)\n",
    "    set_time_limit_sec(m, time_limit)\n",
    "    \n",
    "    #############\n",
    "    #############\n",
    "    # Complete...\n",
    "\n",
    "        # Define variables: x[i,j] is 1 iff we travel between i and j, 0 otherwise. \n",
    "        #     Although we define all n^2 variables, we will only use the (strict) upper triangle. \n",
    "\n",
    "\n",
    "        # Constraint 1: Minimize total length of tour\n",
    "\n",
    "\n",
    "        # Constraint 2: Make x_ij and x_ji be the same thing (undirectional TSP)\n",
    "\n",
    "\n",
    "        # Constraint 3: Don't allow self-arcs, by ensuring diagonal is vector of 0s\n",
    "\n",
    "\n",
    "        # Constraint 4: We must enter and leave every city once and only once\n",
    "    \n",
    "    \n",
    "    #############\n",
    "    #############\n",
    "    \n",
    "    # Lazy constraint\n",
    "    lazy_called = false  \n",
    "    function subtour(cb)\n",
    "        lazy_called = true\n",
    "        # Find any set of cities in a subtour\n",
    "        x_val = callback_value.(Ref(cb), x) # In previous versions, you'd simply use getvalue(x)\n",
    "#         println(x_val)\n",
    "        @time subtour, subtour_length = findSubtour(n, x_val)\n",
    "\n",
    "        if subtour_length == n\n",
    "            # This \"subtour\" is actually all cities, so we are done with this node of the branch and bound tree\n",
    "            return\n",
    "        end\n",
    "\n",
    "        # Subtour found - add lazy constraint\n",
    "        arcs_from_subtour = zero(AffExpr)\n",
    "        for i = 1:n\n",
    "            if subtour[i]\n",
    "            # If this city isn't in subtour, skip it\n",
    "                for j = 1:n\n",
    "                    # Want to include all arcs from this city, which is in the subtour, \n",
    "                    # to all cities not in the subtour\n",
    "                    if (i !=j) && !(subtour[j])\n",
    "                        # j isn't in subtour\n",
    "                        arcs_from_subtour += x[i,j]\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #############\n",
    "        #############\n",
    "        # Complete...\n",
    "        \n",
    "            # Build the subtour elimination constraint here\n",
    "        \n",
    "        \n",
    "        #############\n",
    "        #############\n",
    "        \n",
    "        # Submit built constraint to model via MOI\n",
    "        MOI.submit(m, MOI.LazyConstraint(cb), con)\n",
    "        # Here's how you'd do this in previous JuMP versions:\n",
    "        # @lazyconstraint(cb, arcs_from_subtour >= 2)\n",
    "    end \n",
    "\n",
    "    MOI.set(m, MOI.LazyConstraintCallback(), subtour)\n",
    "    # Here's how you'd do this in previous JuMP versions:\n",
    "    # addlazycallback(m, subtour)\n",
    "    \n",
    "    optimize!(m)\n",
    "\n",
    "    return extractTour(n, value.(x))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function to plot the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_instance(pts) = plot(x = pts[1,:], y = pts[2,:], Geom.point, Guide.xlabel(nothing), Guide.ylabel(nothing))\n",
    "function plot_solution(pts, path, extras = [])\n",
    "\tptspath = pts[:,path]\n",
    "\tplot(x = ptspath[1,:], y = ptspath[2,:], Geom.point, Geom.path, Guide.xlabel(nothing), Guide.ylabel(nothing), extras...)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy Example\n",
    "Next, we solve a small 6 city example (which you might recognize from the diagram above) to verify correctness of our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 6\n",
    "cities =    [50 200;\n",
    "            100 100;\n",
    "            100 300;\n",
    "            500 100;\n",
    "            500 300;\n",
    "            550 200]\n",
    "tour = solveTSP(cities)\n",
    "\n",
    "plot_solution(cities', tour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A more complicated example: TSP in the US\n",
    "What's the quickest tour around the 48 US state capitals in the mainland US?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Source: https://people.sc.fsu.edu/~jburkardt/datasets/tsp/att48.tsp\n",
    "n=48\n",
    "citiesdata=[6734 1453;2233 10;5530 1424;401 841;3082 1644;7608 4458;7573 3716;7265 1268;6898 1885;1112 2049;5468 2606;5989 2873;4706 2674;4612 2035;6347 2683;6107 669;7611 5184;7462 3590;7732 4723;5900 3561;4483 3369;6101 1110;5199 2182;1633 2809;4307 2322;675 1006;7555 4819;7541 3981;3177 756;7352 4506;7545 2801;3245 3305;6426 3173;4608 1198;23 2216;7248 3779;7762 4595;7392 2244;3484 2829;6271 2135;4985 140;1916 1569;7280 4899;7509 3239;10 2676;6807 2993;5185 3258;3023 1942]\n",
    "tour = solveTSP(citiesdata);\n",
    "plot_solution(citiesdata', tour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A larger-scale TSP: Routing a Vehicle\n",
    "Let's try to solve a TSP with 200 cities using the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ludata=readdlm(\"bcl380tsp.txt\")\n",
    "n = 200 #380\n",
    "ludata = ludata[1:n, 2:3] #drop index\n",
    "tour_mip = solveTSP(ludata, time_limit=120.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't work very well!\n",
    "\n",
    "**What went wrong?**\n",
    "\n",
    "a) TSP is NP-hard, so we can't solve it and we should just give up.\n",
    "\n",
    "b) **We have been focusing on lower bounds, but we also need good heuristics to get good upper bounds.**\n",
    "\n",
    "\n",
    "Answer: **(b) [notice that we didn't even find a feasible solution!]**\n",
    "\n",
    "\n",
    "We will use the package TravelingSalesmanHeuristics.jl to generate a high-quality warm-start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pkg> add \"https://github.com/evanfields/TravelingSalesmanHeuristics.jl/\"\n",
    "using TravelingSalesmanHeuristics\n",
    "\n",
    "# Calculate pairwise distance matrix for a heuristic\n",
    "dist = [norm(ludata[i,:] - ludata[j,:]) for i in 1:n, j in 1:n];\n",
    "# Call heuristic solution method\n",
    "Random.seed!(47)\n",
    "tour_heuristic, cost=solve_tsp(dist, quality_factor = 100)\n",
    "cost = sum(dist[tour_heuristic[i],tour_heuristic[i+1]] for i=1:n) + dist[tour_heuristic[n+1],tour_heuristic[1]]\n",
    "println(\"Heuristic method solution cost: $cost\")\n",
    "plot_solution(ludata', tour_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is pretty good, but it turns out that we can obtain a better one after injecting the above solution as a warm-start and rerunning our MIO solver.\n",
    "\n",
    "Let's define a new version of solveTSP which takes a warm start solution, and tunes our solver more cleverly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function solveTSP(cities, warmstart; time_limit = 30.0)\n",
    "\n",
    "    # Calculate pairwise distance matrix\n",
    "    n = size(cities)[1]\n",
    "    dist = [norm(cities[i,:] - cities[j,:]) for i in 1:n, j in 1:n]\n",
    "\n",
    "    m = Model(Gurobi.Optimizer)\n",
    "    set_time_limit_sec(m, time_limit)\n",
    "\n",
    "    # x[i,j] is 1 iff we travel between i and j, 0 otherwise. \n",
    "    # Although we define all n^2 variables, we will only use the (strict) upper triangle. \n",
    "    @variable(m, x[i=1:n,j=1:n], Bin, start=warmstart[i,j])\n",
    "\n",
    "    # Minimize total length of tour\n",
    "    @objective(m, Min, dot(dist, x))\n",
    "\n",
    "    # Make x_ij and x_ji be the same thing (undirectional TSP)\n",
    "    @constraint(m, x.==x')\n",
    "    # Don't allow self-arcs, by ensuring diagonal is vector of 0s\n",
    "    @constraint(m, diag(x).==zeros(n))\n",
    "\n",
    "    # We must enter and leave every city once and only once\n",
    "    for i = 1:n\n",
    "        @constraint(m, sum(x[i,j] for j=1:n) == 2)\n",
    "    end\n",
    "\n",
    "    # Lazy constraint\n",
    "    lazy_called = false  \n",
    "    function subtour(cb)\n",
    "        lazy_called = true\n",
    "        # Find any set of cities in a subtour\n",
    "        x_val = callback_value.(Ref(cb), x)\n",
    "        @time subtour, subtour_length = findSubtour(n, x_val)\n",
    "\n",
    "        if subtour_length == n\n",
    "            # This \"subtour\" is actually all cities, so we are done with this node of the branch and bound tree\n",
    "            return\n",
    "        end\n",
    "\n",
    "        # Subtour found - add lazy constraint\n",
    "        arcs_from_subtour = zero(AffExpr)\n",
    "        for i = 1:n\n",
    "            if subtour[i]\n",
    "            # If this city isn't in subtour, skip it\n",
    "                for j = 1:n\n",
    "                    # Want to include all arcs from this city, which is in the subtour, \n",
    "                    # to all cities not in the subtour\n",
    "                    if (i !=j) && !(subtour[j])\n",
    "                        # j isn't in subtour\n",
    "                        arcs_from_subtour += x[i,j]\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        # Add the subtour elimination constraint\n",
    "        con = @build_constraint(arcs_from_subtour >= 2)\n",
    "        MOI.submit(m, MOI.LazyConstraint(cb), con)\n",
    "    end \n",
    "\n",
    "    MOI.set(m, MOI.LazyConstraintCallback(), subtour)\n",
    "    \n",
    "    optimize!(m)\n",
    "\n",
    "    return extractTour(n, value.(x))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our new solver!\n",
    "Notice that the solution reached is provably optimal (up to solver tolerances)!\n",
    "This also verifies that the heuristic solution obtained earlier is indeed of high-quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#############\n",
    "# Complete...\n",
    "        \n",
    "    # Transform heuristic solution stored in \"tour_heuristic\"\n",
    "    # into a nxn array to give to solver as warm start\n",
    "        \n",
    "        \n",
    "#############\n",
    "#############\n",
    "\n",
    "tour_mip_warm = solveTSP(ludata, warmstart, time_limit=120.0)\n",
    "cost = sum(dist[tour_mip_warm[i],tour_mip_warm[i+1]] for i=1:n) + dist[tour_mip_warm[n+1],tour_mip_warm[1]]\n",
    "println(\"MIP with warm start solution cost: $cost\")\n",
    "plot_solution(ludata', tour_mip_warm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Concorde App\n",
    "* The code laid out above doesn't scale to n=1000s, because of the way we laid out the problem data, and because we aren't using every trick in the book: e.g., we made Julia compute the full distance matrix, which is expensive.\n",
    "\n",
    "* The heuristic we are using is also not quite state-of-the-art: it uses 2-opt swaps, but we get better solutions with 2-opt and 3-opt swaps.\n",
    "\n",
    "* These issues are dealt with in the Concorde TSP code, a state-of-the-art TSP solver which solves TSPs with millions of variables to certifiable optimality by carefully managing its memory and using lots of other \"tricks\" from the literature. \n",
    "\n",
    "**If you have an iPhone, download the (free) Concorde app and try it out!**\n",
    "\n",
    "**See here: http://www.math.uwaterloo.ca/tsp/iphone/index.html, or the app store.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit + References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This material is adapted from previous versions of this course, which have been designed by numerous ORC students.\n",
    "\n",
    "Some of the sources used to create this year's version include:\n",
    " - JuMP documentation\n",
    " - Gurobi documentation\n",
    " - https://orinanobworld.blogspot.com/2012/08/user-cuts-versus-lazy-constraints.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
